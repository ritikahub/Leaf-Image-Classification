{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Libraries\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mahotas as mt\n",
    "from matplotlib import pyplot as plt\n",
    "from skimage import io, measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the dataset folder\n",
    "\n",
    "AllDatasetDirPath = \"C:\\\\Users\\\\Hp\\\\Desktop\\\\Project\\\\Test\"\n",
    "FolderList = my_list = os.listdir(AllDatasetDirPath)\n",
    "print(FolderList) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset():\n",
    "\n",
    "    names = ['area','perimeter','physiological_length','physiological_width','aspect_ratio','rectangularity','circularity', 'major_axis', 'minor_axis', 'convex_area', 'convex_ratio', \\\n",
    "             'mean_r','mean_g','mean_b','stddev_r','stddev_g','stddev_b',  \\\n",
    "             'contrast','correlation','inverse_difference_moments','entropy', \\\n",
    "             'classlabel'\n",
    "            ]\n",
    "    \n",
    "    AllDatasetResults=[]\n",
    "\n",
    "    for i in FolderList:\n",
    "        \n",
    "        df = pd.DataFrame([], columns=names)\n",
    "\n",
    "        print(FolderList.index(i), \"/\", len(FolderList), \"Executing Dataset Name =\", i)\n",
    "        FolderName = i\n",
    "        DATADIR = AllDatasetDirPath+\"/\"+FolderName # Outer Folder Path\n",
    "        # print(DATADIR)\n",
    "\n",
    "        df = pd.DataFrame([], columns=names)  # Create a new dataframe for each folder\n",
    "\n",
    "\n",
    "        for dirname, _, filenames in os.walk(DATADIR):\n",
    "            for filename in filenames:\n",
    "                os.path.join(dirname, filename)\n",
    "\n",
    "        CATEGORIES = os.listdir(DATADIR) \n",
    "        # print(CATEGORIES)\n",
    "\n",
    "        for category in CATEGORIES:\n",
    "            path=os.path.join(DATADIR, category)\n",
    "            # print(path)\n",
    "            myclass = CATEGORIES.index(category)\n",
    "            img_files = os.listdir(path)\n",
    "            # print(img_files)\n",
    "            for file in img_files:\n",
    "                imgpath = path + \"\\\\\" + file\n",
    "                #print(imgpath)\n",
    "                main_img = cv2.imread(imgpath)\n",
    "\n",
    "\n",
    "                # Creating target labels\n",
    "                classlabel = myclass\n",
    "\n",
    "\n",
    "                # Preprocessing\n",
    "\n",
    "                # Convert the image to RGB\n",
    "                img = cv2.cvtColor(main_img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "                # Convert the image to Grayscale\n",
    "                gray = cv2.cvtColor(main_img,cv2.COLOR_BGR2GRAY)\n",
    "                \n",
    "                # Perform thresholding\n",
    "                _, thresholded = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "                \n",
    "                # Find contours\n",
    "                contours, _ = cv2.findContours(thresholded, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "                \n",
    "                # Get the largest contour (assumed to be the leaf)\n",
    "                leaf_contour = max(contours, key=cv2.contourArea)\n",
    "                \n",
    "\n",
    "                # Shape based features\n",
    "                x, y, w, h = cv2.boundingRect(leaf_contour)\n",
    "                area = cv2.contourArea(leaf_contour)\n",
    "                perimeter = cv2.arcLength(leaf_contour, True)\n",
    "                x, y, w, h = cv2.boundingRect(leaf_contour)\n",
    "                physiological_length = max(w, h)\n",
    "                physiological_width = min(w, h)\n",
    "                aspect_ratio = float(physiological_length) / physiological_width\n",
    "                rectangularity = area / (physiological_length * physiological_width)\n",
    "                circularity = (4 * np.pi * area) / (perimeter ** 2)\n",
    "                convex_area = cv2.contourArea(cv2.convexHull(leaf_contour))\n",
    "                convex_ratio = area / convex_area\n",
    "\n",
    "\n",
    "                # Color based features\n",
    "                b, g, r = cv2.split(img)\n",
    "\n",
    "                # Calculate mean and standard deviation for each channel\n",
    "                mean_b = np.mean(b)\n",
    "                mean_g = np.mean(g)\n",
    "                mean_r = np.mean(r)\n",
    "\n",
    "                std_b = np.std(b)\n",
    "                std_g = np.std(g)\n",
    "                std_r = np.std(r)\n",
    "            \n",
    "                \n",
    "                # Texture based features\n",
    "                textures = mt.features.haralick(gray)\n",
    "                ht_mean = textures.mean(axis=0)\n",
    "                contrast = ht_mean[1]\n",
    "                correlation = ht_mean[2]\n",
    "                inverse_diff_moments = ht_mean[4]\n",
    "                entropy = ht_mean[8]\n",
    "                \n",
    "\n",
    "                vector = [area,perimeter,physiological_length,physiological_width,aspect_ratio,rectangularity,circularity,w,h,convex_area,convex_ratio, \\\n",
    "                        mean_r,mean_g,mean_b,std_r,std_g,std_b,\\\n",
    "                        contrast,correlation,inverse_diff_moments,entropy,\\\n",
    "                        classlabel\n",
    "                        ]\n",
    "                \n",
    "                df_temp = pd.DataFrame([vector],columns=names)\n",
    "                df = pd.concat([df, df_temp])\n",
    "                df = df.reset_index(drop=True)\n",
    "\n",
    "            AllDatasetResults.append(df)\n",
    "\n",
    "        #Conversion of dataframe to CSV\n",
    "        df.to_csv(f\"{i}.csv\")\n",
    "\n",
    "    return AllDatasetResults\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = create_dataset()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
