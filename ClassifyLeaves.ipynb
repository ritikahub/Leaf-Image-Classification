{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_and_train(X,Y):\n",
    "\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    #Split dataset into training set and test set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2) #80% training and 20% test\n",
    "    return(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifiers(csv):\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from sklearn.metrics import classification_report\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    from sklearn.svm import SVC\n",
    "    from sklearn.neural_network import MLPClassifier\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    from sklearn.naive_bayes import GaussianNB\n",
    "    from sklearn.decomposition import PCA\n",
    "    from sklearn.pipeline import make_pipeline\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from sklearn.svm import SVC\n",
    "    from sklearn import metrics\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    import matplotlib.pyplot as plt\n",
    "    import scikitplot as skplt\n",
    "\n",
    "\n",
    "    classifier_name=['KNearestNeighbors', 'SVM', 'DecisionTreeClassifier', 'MLPClassifier', 'GaussianNB', 'ANN']\n",
    "\n",
    "    # # Split the data into features (X) and target (y)\n",
    "    # X = df.drop('fraud', axis=1)\n",
    "    # y = df['fraud']\n",
    "\n",
    "    # # Split the data into training and test sets\n",
    "    # X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "    classifiers = [\n",
    "        KNeighborsClassifier(n_neighbors=5),\n",
    "        make_pipeline(StandardScaler(), SVC(gamma='auto')),\n",
    "        DecisionTreeClassifier(),\n",
    "        MLPClassifier(alpha=1, max_iter=1000),\n",
    "        GaussianNB(),\n",
    "        MLPClassifier(random_state=1, max_iter=1000)]\n",
    "    \n",
    "    count = len(classifier_name)\n",
    "    i=0\n",
    "\n",
    "    acc = []\n",
    "    precision = []\n",
    "    recall = []\n",
    "    f1 = []\n",
    "    \n",
    "    for clf in classifiers:\n",
    "        if(i<count):\n",
    "            print(\"\\nAlgo Name.:\", classifier_name[i])\n",
    "            #R1=0;R2=0;R3=0;R4=0;R5=0;R6=0;R7=0;R8=0;R9=0\n",
    "            X_train, X_test, y_train, y_test = test_and_train(X, Y)\n",
    "\n",
    "            # Scale the features using StandardScaler\n",
    "            scaler = StandardScaler()\n",
    "            X_train = scaler.fit_transform(X_train)\n",
    "            X_test = scaler.transform(X_test)\n",
    "\n",
    "            # clf.fit(X_train, np.ravel(y_train)) #To handle ill-defined precision and f1-score error && A column-vector y was passed when a 1d array was expected\n",
    "            global y_pred\n",
    "            clf.fit(X_train, y_train)\n",
    "            y_pred = clf.predict(X_test)\n",
    "            #print(y_pred)\n",
    "\n",
    "\n",
    "            a = accuracy(y_test, y_pred)\n",
    "            print(f\"\\nAlgo Name.: {classifier_name[i]}\\n Accuracy = {a}\", )\n",
    "            acc.append(a*100)\n",
    "#             p = metrics.precision_score(y_test, y_pred)\n",
    "#             precision.append(p*100)\n",
    "#             r = metrics.recall_score(y_test, y_pred)\n",
    "#             recall.append(r*100)\n",
    "#             f1_score = metrics.f1_score(y_test, y_pred)\n",
    "#             f1.append(f1_score*100)\n",
    "            \n",
    "            metrics_csv(classifier_name[i],a)\n",
    "            \n",
    "            print(classification_report(y_test, y_pred, zero_division = 1))\n",
    "            print(\"\\nAlgo Name.:\", classifier_name[i])\n",
    "\n",
    "            i=i+1\n",
    "\n",
    "            #classification_report_to_csv(y_test, y_pred)\n",
    "            plot_confusion_matrix(y_test, y_pred)\n",
    "\n",
    "            \n",
    "            #skplt.metrics.plot_confusion_matrix(y_test, y_pred, figsize=(9,9))\n",
    "\n",
    "            \n",
    "            \n",
    "    print(acc)\n",
    "    print(\"\\n\")\n",
    "    print(\"\\n\")\n",
    "#     print(precision)\n",
    "#     print(\"\\n\")\n",
    "#     print(\"\\n\")\n",
    "#     print(recall)\n",
    "#     print(\"\\n\")\n",
    "#     print(\"\\n\")\n",
    "#     print(f1)\n",
    "#     print(\"\\n\")\n",
    "#     print(\"\\n\")\n",
    "    get_rank(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_test, y_pred):\n",
    "\n",
    "  from sklearn import metrics\n",
    "  #Model Accuracy, how often is the classifier correct?\n",
    "  a = metrics.accuracy_score(y_test, y_pred)\n",
    "  accuracy_upto_two_decimal = \"{:.2f}\".format(a)\n",
    "  print(\"Accuracy:\", accuracy_upto_two_decimal)\n",
    "  return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics_csv(model,a):\n",
    "  #Model Accuracy, how often is the classifier correct?\n",
    "  clf_metrics = [model,a]\n",
    "  AccDF.loc[len(AccDF.index)] = clf_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_report_to_csv(y_test,y_pred):\n",
    "    import pandas as pd\n",
    "    from sklearn.metrics import classification_report\n",
    "    #global dataframe\n",
    "    report = classification_report(y_test, y_pred, output_dict=True, zero_division=1)\n",
    "    #dataframe = pd.DataFrame(report).transpose()\n",
    "    #print(dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_test, y_pred):\n",
    "\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(cm)\n",
    "\n",
    "    ax = sns.heatmap(cm, annot=True, cmap='Blues')\n",
    "\n",
    "    ax.set_title('Confusion Matrix')\n",
    "    ax.set_xlabel('Predicted Values')\n",
    "    ax.set_ylabel('Actual Values')\n",
    "\n",
    "    # Generate tick locations and labels\n",
    "    tick_locations = range(len(target))\n",
    "    tick_labels = target\n",
    "\n",
    "    # Set tick locations and labels for x-axis\n",
    "    ax.set_xticks(tick_locations)\n",
    "    ax.set_xticklabels(tick_labels, rotation=90, fontsize=8)\n",
    "\n",
    "    # Set tick locations and labels for y-axis\n",
    "    ax.set_yticks(tick_locations)\n",
    "    ax.set_yticklabels(tick_labels, fontsize=8)\n",
    "\n",
    "    # Adjust the plot to fit the labels properly\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Display the visualization of the Confusion Matrix.\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "AllDatasetDirPath=\"C:\\\\Users\\\\Hp\\\\Desktop\\\\Project\\\\LeavesFeatures\"\n",
    "FolderList=my_list = os.listdir(AllDatasetDirPath)\n",
    "\n",
    "AllDatasetResults=[]\n",
    "\n",
    "for i in FolderList:\n",
    "    for j in range(16):\n",
    "        print(FolderList.index(i), \"/\", len(FolderList), \"Executing Dataset name =\", i) #0 / 2 Executing Dataset name = A\n",
    "        print(FolderList.index(i), \"/\", len(FolderList), \"Number of iterations =\", j)\n",
    "        FolderName = i\n",
    "        DATADIR =AllDatasetDirPath+\"/\"+FolderName\n",
    "        #print(DATADIR)\n",
    "\n",
    "\n",
    "        #Reading the CSV file\n",
    "        df = pd.read_csv(f\"C:\\\\Users\\HP\\Desktop\\Project\\LeavesFeatures\\\\{i}\")\n",
    "        df = df.dropna()\n",
    "        col=len(df.columns)\n",
    "\n",
    "        df = df.drop_duplicates()\n",
    "\n",
    "        X = df.iloc[:, 1:-1]\n",
    "        Y = df['classlabel']\n",
    "        # Y = df.iloc[:, (col-1):]\n",
    "\n",
    "        from sklearn.preprocessing import StandardScaler\n",
    "        scaler = StandardScaler()\n",
    "        X = scaler.fit_transform(X)\n",
    "\n",
    "        print(f\"Initial Dataset: {X.shape}\")\n",
    "\n",
    "        import pandas as pd\n",
    "        from sklearn.preprocessing import StandardScaler\n",
    "        from sklearn.decomposition import PCA\n",
    "\n",
    "        pca = PCA(n_components=16)  # Reduce to 10 principal components\n",
    "        pca.fit(X)\n",
    "        X = pca.transform(X)\n",
    "        print(f\"After PCA, Shape of the dataset: {X.shape}\")\n",
    "\n",
    "\n",
    "        import pandas as pd\n",
    "\n",
    "\n",
    "        # Calculate the mean of each column\n",
    "        column_means = df.mean()\n",
    "\n",
    "        # Print the mean of each column\n",
    "        print(\"Mean of each column:\")\n",
    "        print(column_means)\n",
    "\n",
    "\n",
    "        plt.figure(figsize=(8,6))\n",
    "        plt.scatter(X[:,0],X[:,1],c=df['classlabel'])\n",
    "        plt.xlabel('First principle component')\n",
    "        plt.ylabel('Second principle component')\n",
    "\n",
    "        global test\n",
    "        global lables\n",
    "        global target_class\n",
    "        global target\n",
    "\n",
    "        test=np.array(Y)\n",
    "        lables = test.flatten()\n",
    "\n",
    "        target_class = set(lables)\n",
    "        target = list(target_class)\n",
    "\n",
    "        df.shape #Shape of dataset\n",
    "\n",
    "        classifiers(i)\n",
    "    AccDF.to_csv(f\"{i}.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: When ``true positive + false positive == 0``, precision is undefined.   When ``true positive + false negative == 0``, recall is undefined.   In such cases, by default the metric will be set to 0, as will f-score,   and ``UndefinedMetricWarning`` will be raised. This behavior can be   modified with ``zero_division``"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
